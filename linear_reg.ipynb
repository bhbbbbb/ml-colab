{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ydS7I2DuV0kQ"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "\n",
        "# you can modify the function\n",
        "def create_data(x):\n",
        "    return (0.6*x+10) + np.random.normal(0,0.3)\n",
        "    #                   error term      (mean, variance)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Kh5CDRTVe4vX"
      },
      "outputs": [],
      "source": [
        "#create domain of x ( datapoints in x)\n",
        "dom = np.linspace(0,30,50)\n",
        "#                (start, end, number of points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Ca2R58-TWeZ6"
      },
      "outputs": [],
      "source": [
        "dataset = []\n",
        "for i in dom:\n",
        "    (x, y) = (i, create_data(i))\n",
        "    dataset.append((x,y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UvKEyrywenCa"
      },
      "outputs": [],
      "source": [
        "# dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7kRyJS0SWlCE"
      },
      "outputs": [],
      "source": [
        "# visualize the data\n",
        "fig = plt.figure(figsize=(8,8))\n",
        "ax = fig.add_subplot(111)\n",
        "for x , y in dataset:\n",
        "    plt.scatter(x,y)\n",
        "plt.xlim(0,25)\n",
        "plt.ylim(0,25)\n",
        "ax.set_aspect('equal', adjustable = 'box')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "546pxIeRXGPA"
      },
      "outputs": [],
      "source": [
        "# calculate the sum of the loss \n",
        "def criterion(w, b, dataset):\n",
        "    return sum(((w * x + b) - y) ** 2 for x, y in dataset)\n",
        "\n",
        "# calculate the sum of the gradient with respect to w\n",
        "def d_criterion(w, b, dataset):\n",
        "    return sum(2 * x * (w * x + b - y) for x, y in dataset)\n",
        "\n",
        "# calculate the sum of the gradient with respect to b\n",
        "def d_bias(w, b, dataset):\n",
        "    return sum(2 * (w * x + b - y) for x, y in dataset)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Xz-HwFUgZ_hc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss: 19559.25\n",
            "w: 0.33\n",
            "b: 0.02\n",
            "loss: 985.32\n",
            "w: 1.04\n",
            "b: 1.25\n",
            "loss: 763.36\n",
            "w: 0.98\n",
            "b: 2.30\n",
            "loss: 591.60\n",
            "w: 0.94\n",
            "b: 3.22\n",
            "loss: 458.70\n",
            "w: 0.90\n",
            "b: 4.04\n",
            "loss: 355.87\n",
            "w: 0.86\n",
            "b: 4.75\n",
            "loss: 276.29\n",
            "w: 0.83\n",
            "b: 5.38\n",
            "loss: 214.72\n",
            "w: 0.80\n",
            "b: 5.93\n",
            "loss: 167.08\n",
            "w: 0.78\n",
            "b: 6.42\n",
            "loss: 130.21\n",
            "w: 0.76\n",
            "b: 6.85\n",
            "loss: 101.69\n",
            "w: 0.74\n",
            "b: 7.23\n",
            "loss: 79.61\n",
            "w: 0.72\n",
            "b: 7.56\n",
            "loss: 62.53\n",
            "w: 0.71\n",
            "b: 7.85\n",
            "loss: 49.32\n",
            "w: 0.70\n",
            "b: 8.10\n",
            "loss: 39.09\n",
            "w: 0.69\n",
            "b: 8.33\n",
            "loss: 31.18\n",
            "w: 0.68\n",
            "b: 8.53\n",
            "loss: 25.06\n",
            "w: 0.67\n",
            "b: 8.70\n",
            "loss: 20.32\n",
            "w: 0.66\n",
            "b: 8.86\n",
            "loss: 16.65\n",
            "w: 0.65\n",
            "b: 8.99\n",
            "loss: 13.82\n",
            "w: 0.65\n",
            "b: 9.11\n",
            "loss: 11.62\n",
            "w: 0.64\n",
            "b: 9.21\n",
            "loss: 9.92\n",
            "w: 0.64\n",
            "b: 9.31\n",
            "loss: 8.61\n",
            "w: 0.63\n",
            "b: 9.39\n",
            "loss: 7.59\n",
            "w: 0.63\n",
            "b: 9.46\n",
            "loss: 6.80\n",
            "w: 0.63\n",
            "b: 9.52\n",
            "loss: 6.20\n",
            "w: 0.62\n",
            "b: 9.58\n",
            "loss: 5.72\n",
            "w: 0.62\n",
            "b: 9.62\n",
            "loss: 5.36\n",
            "w: 0.62\n",
            "b: 9.67\n",
            "loss: 5.08\n",
            "w: 0.62\n",
            "b: 9.70\n",
            "loss: 4.86\n",
            "w: 0.62\n",
            "b: 9.74\n",
            "loss: 4.69\n",
            "w: 0.61\n",
            "b: 9.77\n",
            "loss: 4.56\n",
            "w: 0.61\n",
            "b: 9.79\n",
            "loss: 4.46\n",
            "w: 0.61\n",
            "b: 9.81\n",
            "loss: 4.38\n",
            "w: 0.61\n",
            "b: 9.83\n",
            "loss: 4.32\n",
            "w: 0.61\n",
            "b: 9.85\n",
            "loss: 4.27\n",
            "w: 0.61\n",
            "b: 9.87\n",
            "loss: 4.24\n",
            "w: 0.61\n",
            "b: 9.88\n",
            "loss: 4.21\n",
            "w: 0.61\n",
            "b: 9.89\n",
            "loss: 4.19\n",
            "w: 0.61\n",
            "b: 9.90\n",
            "loss: 4.17\n",
            "w: 0.61\n",
            "b: 9.91\n",
            "loss: 4.16\n",
            "w: 0.61\n",
            "b: 9.92\n",
            "loss: 4.15\n",
            "w: 0.61\n",
            "b: 9.93\n",
            "loss: 4.14\n",
            "w: 0.61\n",
            "b: 9.93\n",
            "loss: 4.13\n",
            "w: 0.61\n",
            "b: 9.94\n",
            "loss: 4.13\n",
            "w: 0.61\n",
            "b: 9.94\n",
            "loss: 4.12\n",
            "w: 0.61\n",
            "b: 9.95\n",
            "loss: 4.12\n",
            "w: 0.61\n",
            "b: 9.95\n",
            "loss: 4.12\n",
            "w: 0.61\n",
            "b: 9.95\n",
            "loss: 4.12\n",
            "w: 0.61\n",
            "b: 9.96\n",
            "loss: 4.12\n",
            "w: 0.61\n",
            "b: 9.96\n",
            "loss: 4.12\n",
            "w: 0.61\n",
            "b: 9.96\n",
            "loss: 4.12\n",
            "w: 0.61\n",
            "b: 9.96\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.96\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.97\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.97\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.97\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.97\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.97\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.97\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.97\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.97\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.97\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.97\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.97\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.97\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.97\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.97\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.98\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.98\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.98\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.98\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.98\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.98\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.98\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.98\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.98\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.98\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.98\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.98\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.98\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.98\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.98\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.98\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.98\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.98\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.98\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.98\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.98\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.98\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.98\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.98\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.98\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.98\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.98\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.98\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.98\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.98\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.98\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.98\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.98\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.98\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.98\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.98\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.98\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.98\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.98\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.98\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.98\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.98\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.98\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.98\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.98\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.98\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.98\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.98\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.98\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.98\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.98\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.98\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.98\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.98\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.98\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.98\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.98\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.98\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.98\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.98\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.98\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.98\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.98\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.98\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.98\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.98\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.98\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.98\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.98\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.98\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.98\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.98\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.98\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.98\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.98\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.98\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.98\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.98\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.98\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.98\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.98\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.98\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.98\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.98\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.98\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.98\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.98\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.98\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.98\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.98\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.98\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.98\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.98\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.98\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.98\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.98\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.98\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.98\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.98\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.98\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.98\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.98\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.98\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.98\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.98\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.98\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.98\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.98\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.98\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.98\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.98\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.98\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.98\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.98\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.98\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.98\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.98\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.98\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.98\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.98\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.98\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.98\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.98\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.98\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.98\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.98\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.98\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.98\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.98\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.98\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.98\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.98\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.98\n",
            "loss: 4.11\n",
            "w: 0.60\n",
            "b: 9.98\n"
          ]
        }
      ],
      "source": [
        "# parameters and hyper-parameteres\n",
        "w = 0\n",
        "b = 0\n",
        "learning_rate = 0.00001\n",
        "# gradient descent\n",
        "for epoch in range(100000):\n",
        "    loss = criterion(w, b, dataset)\n",
        "    ### Modify here\n",
        "    grad_wrt_w = d_criterion(w, b, dataset)\n",
        "    grad_wrt_b = d_bias(w, b, dataset)\n",
        "    w = w - learning_rate * grad_wrt_w\n",
        "    b = b - learning_rate * grad_wrt_b\n",
        "    ### End of Modify\n",
        "    # log metrics every 500 epochs\n",
        "    if(epoch %499==0):\n",
        "        print(\"loss: {:0.2f}\".format(loss))\n",
        "        print(\"w: {:0.2f}\".format(w))\n",
        "        print(\"b: {:0.2f}\".format(b))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eweYQFzI28rj"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "linear_reg.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "934329bf01ff6b4f05f823830b4f8aae0335dfa7fa4014eb40f8bf8c13bc3d86"
    },
    "kernelspec": {
      "display_name": "Python 2.7.16 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.11"
    },
    "metadata": {
      "interpreter": {
        "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
